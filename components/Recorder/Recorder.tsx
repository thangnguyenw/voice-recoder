'use client';

import { useState, useRef } from 'react';
import { Switch } from '@headlessui/react';
import { Mic, MicOff } from 'lucide-react';
import { useWebSocket } from '@/contexts/WebSocketContext';
import CanvasWaveform from './CanvasWaveform';
import AuthModal from '../modals/AuthModal';
import ManualButton from './ManualButton';

export default function Recorder() {
  const [mode, setMode] = useState<'voice' | 'manual'>('voice');
  const [recordingMode, setRecordingMode] = useState<'once' | 'continuous'>('once');
  const [recognitionMode, setRecognitionMode] = useState(true);
  const [isRecording, setIsRecording] = useState(false);
  const [audioURL, setAudioURL] = useState<string | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const [pendingSwitchValue, setPendingSwitchValue] = useState<boolean | null>(null);
  const [showModal, setShowModal] = useState(false);
  const [buttonState, setButtonState] = useState<'off' | 'transitioning-on' | 'on' | 'transitioning-off'>('off');
  const isRecordingRef = useRef(false);
  const manuallyStoppedRef = useRef(false);

  const { sendAudio } = useWebSocket();

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunks.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks.current, { type: 'audio/webm' });
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudioURL(audioUrl);

        const buffer = await audioBlob.arrayBuffer();
        sendAudio(buffer);
      };

      mediaRecorder.start();
      setIsRecording(true);
      isRecordingRef.current = true;

      setTimeout(() => {
        stopRecording();
      }, 2000);
    } catch (err) {
      console.error('‚ùå L·ªói khi ghi √¢m:', err);
    }
  };

  // const startContinuousRecording = async () => {
  //   try {
  //     const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  //     streamRef.current = stream;
  //     setIsRecording(true);
  
  //     const recordChunk = async () => {
  //       if (!isRecording || !streamRef.current) return;
  
  //       const mediaRecorder = new MediaRecorder(streamRef.current);
  //       const chunks: Blob[] = [];
  
  //       // mediaRecorder.ondataavailable = (event) => {
  //       //   if (event.data.size > 0) {
  //       //     chunks.push(event.data);
  //       //   }
  //       // };
  
  //       mediaRecorder.onstop = async () => {
  //         const blob = new Blob(chunks, { type: 'audio/webm' });
  //         const buffer = await blob.arrayBuffer();
  //         sendAudio(buffer);
  
  //         // ti·∫øp t·ª•c ghi chunk ti·∫øp theo n·∫øu v·∫´n ƒëang ghi
  //         if (isRecording) {
  //           setTimeout(recordChunk, 50); // delay gi·ªØa c√°c chunk
  //         }
  //       };
  
  //       mediaRecorder.start();
  //       mediaRecorderRef.current = mediaRecorder;
  
  //       setTimeout(() => {
  //         mediaRecorder.stop(); // s·∫Ω k√≠ch ho·∫°t onstop
  //       }, 2000); // m·ªói chunk 2s
  //     };
  
  //     recordChunk(); // b·∫Øt ƒë·∫ßu chu·ªói ghi li√™n t·ª•c
  //   } catch (err) {
  //     console.error('L·ªói ghi √¢m li√™n t·ª•c:', err);
  //   }
  // };
  const startContinuousRecording = async () => {
    try {
      console.log('üé§ B·∫Øt ƒë·∫ßu ghi √¢m li√™n t·ª•c...');
  
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
  
      setIsRecording(true);
      isRecordingRef.current = true;
  
      const recordChunk = async () => {
        if (!isRecordingRef.current || !streamRef.current) {
          console.log('‚õî D·ª´ng ghi v√¨ isRecording = false ho·∫∑c stream null');
          return;
        }
  
        console.log('üü¢ B·∫Øt ƒë·∫ßu chunk m·ªõi');
  
        const mediaRecorder = new MediaRecorder(streamRef.current);
        const chunks: Blob[] = [];
  
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            chunks.push(event.data);
            console.log('üì¶ Nh·∫≠n ƒë∆∞·ª£c chunk data:', event.data.size, 'bytes');
          }
        };
  
        mediaRecorder.onstop = async () => {
          console.log('üõë D·ª´ng ghi chunk');
  
          const blob = new Blob(chunks, { type: 'audio/webm' });
          console.log('üìÑ Blob size:', blob.size);
  
          const buffer = await blob.arrayBuffer();
          console.log('üì§ G·ª≠i d·ªØ li·ªáu t·ªõi server (buffer size):', buffer.byteLength);
  
          sendAudio(buffer);
  
          if (isRecordingRef.current) {
            console.log('üîÅ Chu·∫©n b·ªã ghi chunk ti·∫øp theo sau 1s...');
            setTimeout(recordChunk, 1000); // delay gi·ªØa c√°c chunk
          } else {
            console.log('üßä D·ª´ng v√≤ng l·∫∑p ghi v√¨ isRecording = false');
          }
        };
  
        mediaRecorder.start();
        mediaRecorderRef.current = mediaRecorder;
  
        console.log('‚è±Ô∏è S·∫Ω d·ª´ng chunk sau 2 gi√¢y...');
        setTimeout(() => {
          if (mediaRecorder.state === 'recording') {
            mediaRecorder.stop(); // s·∫Ω k√≠ch ho·∫°t onstop
          }
        }, 2000);
      };
  
      recordChunk(); // b·∫Øt ƒë·∫ßu chu·ªói ghi li√™n t·ª•c
    } catch (err) {
      console.error('‚ùå L·ªói ghi √¢m li√™n t·ª•c:', err);
    }
  };
  

  const stopRecording = () => {
    console.log('üßç‚Äç‚ôÇÔ∏è Ng∆∞·ªùi d√πng b·∫•m d·ª´ng ghi');
  
    setIsRecording(false);
    isRecordingRef.current = false;
  
    mediaRecorderRef.current?.stop();
    streamRef.current?.getTracks().forEach((track) => track.stop());
  
    if (manuallyStoppedRef.current) {
      streamRef.current = null;
      mediaRecorderRef.current = null;
    }
  };

  const handleRecordButton = () => {
    if (isRecording) {
      manuallyStoppedRef.current = true; // üßç‚Äç‚ôÇÔ∏è Ng∆∞·ªùi d√πng b·∫•m d·ª´ng
      stopRecording();
    } else {
      if (recordingMode === 'once') {
        startRecording();
      } else {
        manuallyStoppedRef.current = false; // üîÅ Chu·∫©n b·ªã ghi li√™n t·ª•c
        startContinuousRecording();
      }
    }
  };

  const handleToggleRecognition = (newValue: boolean) => {
    if (!newValue) {
      setPendingSwitchValue(newValue);
      setShowModal(true);
    } else {
      setRecognitionMode(true);
    }
  };

  const handleConfirm = (username: string, password: string) => {
    if (pendingSwitchValue === false) {
      setRecognitionMode(false);
    }
    setShowModal(false);
    setPendingSwitchValue(null);
  };

  return (
    <div className="w-full">
      <div className="col-span-2 bg-white shadow-md rounded-xl p-6">
        <div className="flex justify-between items-center mb-4 flex-wrap gap-4">
          <h2 className="text-xl font-semibold">ƒêi·ªÅu khi·ªÉn h·ªá th·ªëng</h2>

          <div className="flex items-center gap-4">
            {mode === 'voice' && (
              <div className="flex items-center gap-2">
                <span className="text-sm text-gray-600 whitespace-nowrap">
                  Nh·∫≠n di·ªán ng∆∞·ªùi n√≥i
                </span>
                <Switch
                  checked={recognitionMode}
                  onChange={handleToggleRecognition}
                  className={`$ {
                    recognitionMode ? 'bg-green-500' : 'bg-gray-300'
                  } relative inline-flex h-6 w-11 items-center rounded-full transition-colors`}
                >
                  <span
                    className={`$ {
                      recognitionMode ? 'translate-x-6' : 'translate-x-1'
                    } inline-block h-4 w-4 transform rounded-full bg-white transition`}
                  />
                </Switch>
              </div>
            )}

            <div className="flex items-center gap-1 bg-gray-100 px-2 py-1 rounded-lg">
              <button
                onClick={() => setMode('voice')}
                className={`px-3 py-1 rounded-md text-sm font-medium $ {
                  mode === 'voice' ? 'bg-blue-500 text-white' : 'text-gray-700'
                }`}
              >
                üéôÔ∏è Gi·ªçng n√≥i
              </button>
              <button
                onClick={() => setMode('manual')}
                className={`px-3 py-1 rounded-md text-sm font-medium $ {
                  mode === 'manual' ? 'bg-blue-500 text-white' : 'text-gray-700'
                }`}
              >
                ‚úã Th·ªß c√¥ng
              </button>
            </div>

            <div className="flex items-center gap-3">
              <span className="text-sm">Ch·∫ø ƒë·ªô:</span>
              <select
                className="border rounded px-2 py-1 text-sm"
                value={recordingMode}
                onChange={(e) => setRecordingMode(e.target.value as 'once' | 'continuous')}
              >
                <option value="once">Ghi 5 gi√¢y</option>
                <option value="continuous">Ghi li√™n t·ª•c</option>
              </select>
            </div>
          </div>

          <AuthModal
            show={showModal}
            title={`Confirm switching to $ {
              recognitionMode ? 'normal' : 'recognition'
            } mode`}
            onCancel={() => setShowModal(false)}
            onConfirm={handleConfirm}
          />
        </div>

        <div className="min-h-[300px] transition-all duration-300">
          {mode === 'voice' ? (
            <>
              <div className="flex flex-col items-center justify-center text-center h-60 text-gray-400">
                {isRecording ? (
                  <>
                    <Mic size={64} strokeWidth={1.5} className="text-red-500 animate-pulse" />
                    <p className="mt-3 text-base text-red-600">ƒêang ghi √¢m...</p>
                  </>
                ) : (
                  <>
                    <MicOff size={64} strokeWidth={1.2} />
                    <p className="mt-3 text-base">H·ªá th·ªëng ƒëang t·∫Øt ch·∫ø ƒë·ªô nh·∫≠n di·ªán</p>
                  </>
                )}
                <div className="mt-4 w-full">
                  <CanvasWaveform active={isRecording} reset={!isRecording} />
                </div>
              </div>

              <div className="flex justify-center items-center mt-2 gap-6 flex-wrap">
                <button
                  onClick={handleRecordButton}
                  className={`px-8 py-3.5 $ {
                    isRecording
                      ? 'bg-red-500 hover:bg-red-600'
                      : 'bg-[#6B7280] hover:bg-[#4B5563]'
                  } text-white rounded-full shadow flex items-center gap-2 transition`}
                >
                  {isRecording ? (
                    <>
                      <MicOff size={18} /> Stop recording
                    </>
                  ) : (
                    <>
                      <Mic size={18} /> Start recording
                    </>
                  )}
                </button>

                {audioURL && (
                  <audio controls src={audioURL} className="max-w-[200px]" />
                )}
              </div>
            </>
          ) : (
            <div className="flex flex-col items-center justify-center text-center h-60">
              {mode === 'manual' && (
                <ManualButton buttonState={buttonState} setButtonState={setButtonState} />
              )}
            </div>
          )}
        </div>
      </div>
    </div>
  );
}
